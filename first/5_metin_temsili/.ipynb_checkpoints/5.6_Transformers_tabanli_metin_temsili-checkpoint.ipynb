{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fd0834c3-5583-4f68-b2cd-e41a86baad55",
   "metadata": {},
   "source": [
    "transformers tabanlı metin temsili\n",
    "Dikkat mekanizmasını kullanarak her bir öğenin diğer kelimlerle olan ilişkilerini öğrenmektedir. bu özellik sayesinde uzun metinlerde bağlamı anlamada yardımcı olmaktadır.\n",
    "paralel işleme yeteneği sayesinde çeviri işlemlerinde kullanılabilir.\n",
    "en bilindik transformers modelleri- > Bert, GPT ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1308593-6862-419a-bb7c-43a9f5909f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fca79a-8671-4b71-a03d-bdc2c206c1d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "AutoTokenizer is designed to be instantiated using the `AutoTokenizer.from_pretrained(pretrained_model_name_or_path)` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#model ve tokenizer yükle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:712\u001b[0m, in \u001b[0;36mAutoTokenizer.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 712\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    713\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer is designed to be instantiated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    714\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing the `AutoTokenizer.from_pretrained(pretrained_model_name_or_path)` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    715\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: AutoTokenizer is designed to be instantiated using the `AutoTokenizer.from_pretrained(pretrained_model_name_or_path)` method."
     ]
    }
   ],
   "source": [
    "#model ve tokenizer yükle\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44294b61-96b7-488b-af1a-5611ad49c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input text (metni) tanimla\n",
    "text = \"Transformers can be used gor natural language prosessing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b350a-3d59-4610-8931-3ac5c42be67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metni tokenlere çevir\n",
    "inputs = tokenizer(text, return_tensor = \"pt\") # çıktı pytorch tensoru olarak return edilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6ceee-c056-41eb-a75c-f9c7bdcfcb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeli kullanarak metin temsili oluştur\n",
    "with torch.no_grad(): #gradyanların hesaplanması durdurulur böylece daha verimli kullanırız. \n",
    "    model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10b727-566b-4c94-b6b1-0620e4ba68e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelin çıkışından son gizli durumu alalım \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c1b72-220e-461a-bbdf-151d295d52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ilk tokenin embedding ini alalım ve print ettirelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad214d-a71e-4f54-af4d-a95e52318149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2403e2-36c3-4965-8448-0bd3e2b24c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

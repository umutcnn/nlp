{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3d95bf-f11e-4d2c-a894-2923c652ec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700a1563dbc948dab7c5d0fe70d01bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import libraies\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc18ebff-66ae-4c07-b601-215568bcf480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1fd5e6-9cf5-450c-9efc-6e38f8ba181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# squad veri seti uzerinde ince ayar yapilmis bert fil modeli\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e020d271-0fa8-46b0-aa1b-3cef0323bb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a225dbfde4ea4fa69520227769450fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324eef9a47a54f0d842172e414b06bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc0e61087464126987959cf1eecfdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48083384b1084c44a05f06bf691e162a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bert tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6f5279-68f7-4894-82b5-be613168f033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5861ae4a5ea426eadb82e260dfb0486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# soru cevaplama gorevi icin ince ayar yapilmis bert modeli\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ee4cf-5ff9-4353-bbb4-2f7c826d10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soru-Cevap Tahmini Fonksiyonu\n",
    "\n",
    "def predict_answer(context, question):\n",
    "    \"\"\"\n",
    "    verilen bir metin (context) ve bir soru (question) kullanarak\n",
    "    metin içerisinden cevabı tahmin eder.\n",
    "\n",
    "    adım adım ne yaptığı şu şekilde özetlenebilir:\n",
    "\n",
    "    1. metin ve soruyu tokenize eder.\n",
    "    2. token'lar üzerinden modele uygun input verilerini oluşturur.\n",
    "    3. modeli çalıştırarak, cevabın başlayabileceği ve bitebileceği yerlerin skorlarını alır.\n",
    "    4. bu skorlar arasından en yüksek skora sahip başlangıç ve bitiş indekslerini seçer.\n",
    "    5. ilgili token ID'lerini metin haline getirerek cevabı çıkarır.\n",
    "    6. cevabı okunabilir bir string formatına dönüştürerek döner.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. encode_plus ile hem soru hem metin birlikte token'lara ayrılır.\n",
    "    # max_length: 512, çünkü transformer'lar genelde maksimum bu kadar token alabilir.\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        question,\n",
    "        context,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # 2. giriş verileri hazırlanır\n",
    "    input_ids = encoding[\"input_ids\"]  # Token ID'leri\n",
    "    attention_mask = encoding[\"attention_mask\"]  # Dikkate alınacak token'lar maskelenir\n",
    "\n",
    "    # 3. model çalıştırılır, ama gradyan hesabı yapmadan (inference modu)\n",
    "    with torch.no_grad():\n",
    "        start_scores, end_scores = model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=False\n",
    "        )\n",
    "\n",
    "    # 4. skorlar içerisinden en yüksek olasılıkların indeksleri alınır\n",
    "    start_index = torch.argmax(start_scores, dim=1).item()  # Cevabın başlayabileceği en yüksek skorlu index\n",
    "    end_index = torch.argmax(end_scores, dim=1).item()  # Cevabın bitebileceği en yüksek skorlu index\n",
    "\n",
    "    # 5. token ID'lerini alarak cevabın geçtiği token'ları bul\n",
    "    answer_tokens = tokenizer.convert_ids_to_tokens(\n",
    "        input_ids[0][start_index:end_index + 1]\n",
    "    )\n",
    "\n",
    "    # 6. token'ları okunabilir string haline getiriyoruz\n",
    "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45ef6b-3457-4b3d-b968-4d0373d33572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01db1de-9c4d-45ab-897e-1d225528b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face transformers kütüphanesinden tokenizer ve model sınıflarını içe aktar\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d9c137-a80a-43b9-8759-76cd190c6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uyarıları gizlemek için warnings kütüphanesi kullanılıyor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # konsolda uyarı mesajlarını gizle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad83d278-6d57-48df-b6e9-5dab52f577ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kullanılacak modelin adı (GPT-2 modeli)\n",
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2449a795-f1c6-4994-854f-e62632530be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be26d01eeb149c5ad05754d6e70b464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5604bfff664a4429b0edbd35142f3ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05dc80b285144626b86004227b315b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d414684527c84e7ab2c5b318aff77998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e90ec67e76485990a8bd3983f2d878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# modelle birlikte kullanılacak tokenizeri yükle\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538070d7-8b97-4937-ac03-b08058dec3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f39a5b77f44a7f83278dbf057a839a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a569f27fd094c4db08a68e16beee51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gpt2 modelini yükle (dil modeli başlığı ile birlikte, yani metin üretmeye hazır)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fceaa3bd-4431-413c-b505-dfa839ea7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soru ve bağlama göre cevap üreten fonksiyon\n",
    "def generate_answer(context, question):\n",
    "    # giriş metni: bağlam ve soru birleştiriliyor\n",
    "    input_text = f\"Question: {question}, Context: {context}. Please answer the question according to context\"\n",
    "    \n",
    "    # tokenizer ile giriş metni sayısallaştırılıyor (input_ids elde edilir)\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")  # Tensor formatında, PyTorch ile çalışmak için\n",
    "    \n",
    "    # modelin tahmin işlemi yapılırken gradyan hesaplamasını kapat (daha az bellek kullanılır)\n",
    "    with torch.no_grad():\n",
    "        # modelden cevap üret. `max_length=300` ile maksimum üretilecek token sayısı sınırlandırılmış\n",
    "        outputs = model.generate(inputs, max_length=300)\n",
    "        \n",
    "    # modelin oluşturduğu token'ları tekrar insan tarafından okunabilir metne çevir\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)  # Özel tokenlar (örn. <EOS>) çıkarılır\n",
    "    \n",
    "    # eger üretim sonucunda 'answer:' bölümü varsa onu ayıklıyoruz\n",
    "    answer = answer.split(\"Answer:\")[-1].strip()\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2545c37e-ae13-4d89-b4c3-5820926b05ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The capital of France is Paris.\n",
      "\n",
      "Question: What is the capital of France, Context: France, officially the French Republic,\n"
     ]
    }
   ],
   "source": [
    "# ilk örnek: Fransa'nın başkentini sorma\n",
    "question = \"What is the capital of France\"\n",
    "context = \"France, officially the French Republic, is a country whose capital is Paris\"\n",
    "\n",
    "# fonksiyonu çalıştır ve cevabı al\n",
    "answer = generate_answer(context, question)\n",
    "print(f\"Answer: {answer}\")  # Beklenen çıktı: Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ef0981-a588-4e66-b729-7c295a718210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Question: What is Machine Learning?, Context: Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance \n",
      "                on a specific task. Machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or \n",
      "                decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection \n",
      "                of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning \n",
      "                is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, \n",
      "                theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory \n",
      "                data analysis through unsupervised learning.In its application across business problems, machine learning is also referred to as predictive analytics. . Please answer the question according to context.\n"
     ]
    }
   ],
   "source": [
    "# ikinci örnek: Makine öğrenmesi nedir?\n",
    "question = '''What is Machine Learning?'''\n",
    "context = '''Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance \n",
    "                on a specific task. Machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or \n",
    "                decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection \n",
    "                of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning \n",
    "                is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, \n",
    "                theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory \n",
    "                data analysis through unsupervised learning.In its application across business problems, machine learning is also referred to as predictive analytics. '''\n",
    "\n",
    "# fonksiyonu çalıştır ve cevabı al\n",
    "answer = generate_answer(context, question)\n",
    "print(f\"Answer: {answer}\")  # beklenen çıktı: ML'in tanımı (üretilecek metne bağlı)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f828184-6134-4055-af6d-4c2e7883a744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

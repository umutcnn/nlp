{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f99d611-b925-4e84-9941-65a5c735a4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\UMUT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\UMUT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\UMUT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\UMUT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\UMUT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc647682-f269-42c9-aa00-fcfbee1d4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veri setini yukle  duygu_analizi_amazon_veri_seti.csv\n",
    "df = pd.read_csv(\"duygu_analizi_amazon_veri_seti.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b732a7b-3463-4748-bebc-a09ab8fd4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning ve preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_preprocess_data(text):\n",
    "    \n",
    "    # 1. küçük harfe çevir ve tokenize et\n",
    "    tokens = word_tokenize(text.lower())  \n",
    "    # Örn: \"This is a GOOD book.\" -> ['this', 'is', 'a', 'good', 'book', '.']\n",
    "    \n",
    "    # 2. stopwordleri çıkar (önemsiz kelimeler: is, the, and vs.)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words(\"english\")]\n",
    "    # Örn: ['good', 'book', '.']\n",
    "\n",
    "    # 3. lemmatize et (kelimeleri kök forma indir)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    # Örn: ['good', 'book', '.'] (bazı kelimeler değişebilir: 'books' -> 'book')\n",
    "\n",
    "    # 4. tekrar metne dönüştür\n",
    "    processed_text = \" \".join(lemmatized_tokens)\n",
    "    # ['good', 'book'] -> \"good book\"\n",
    "    \n",
    "    return processed_text\n",
    "    \n",
    "# dataFrame'deki \"reviewText\" sütununa temizlik işlemi uygula\n",
    "df[\"reviewText2\"] = df[\"reviewText\"].apply(clean_preprocess_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f71c08-6639-4a67-a215-076685ee380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis(nltk)\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 1. Ardından, \"get_sentiments\" adında bir fonksiyon tanımlıyoruz.\n",
    "# Bu fonksiyon, bir metin alıyor ve analiz edip pozitif mi değil mi diye karar veriyor.\n",
    "def get_sentiments(text):\n",
    "    # a. \"polarity_scores\" metodu, verilen metindeki olumlu, olumsuz, nötr ve genel duygu puanlarını döndürür.\n",
    "    score = analyzer.polarity_scores(text)\n",
    "\n",
    "    # b. Burada basit bir mantık kullanılmış: Eğer pozitif skor sıfırdan büyükse bu metin olumlu kabul ediliyor.\n",
    "    #    Böylece sonuç ikili hale getirilmiş oluyor: 1 = pozitif, 0 = değil.\n",
    "    sentiment = 1 if score[\"pos\"] > 0 else 0\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "# 2. Son olarak, elimizdeki metin verisine bu duygu analizini uyguluyoruz.\n",
    "# \"reviewText2\" sütunundaki ön işlenmiş metinlere analiz fonksiyonu uygulanarak yeni bir sütun oluşturuluyor.\n",
    "df[\"sentiment\"] = df[\"reviewText2\"].apply(get_sentiments)\n",
    "\n",
    "# Bu işlem sonucunda, artık elimizde her bir yoruma ait bir duygu sınıflandırması (pozitif/negatif) olacak.\n",
    "# Bu sınıflandırma, örneğin bir ürünün müşteri memnuniyetini analiz etme veya yorum filtreleme gibi alanlarda kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e6ee6a-9f95-40c9-9341-c5338a807f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: [[ 1131  3636]\n",
      " [  576 14657]]\n"
     ]
    }
   ],
   "source": [
    "# evaluation - test\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(df[\"Positive\"], df[\"sentiment\"])\n",
    "print(f\"Confusion matrix: {cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca63dd5d-f139-440f-80b6-c5f26d945191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.24      0.35      4767\n",
      "           1       0.80      0.96      0.87     15233\n",
      "\n",
      "    accuracy                           0.79     20000\n",
      "   macro avg       0.73      0.60      0.61     20000\n",
      "weighted avg       0.77      0.79      0.75     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(df[\"Positive\"], df[\"sentiment\"])\n",
    "\n",
    "print(f\"Classification report: \\n{cr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f67b1b-8b4e-4a63-8ada-96554c32413b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
